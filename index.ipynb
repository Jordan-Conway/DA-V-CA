{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "\n",
    "# Encoding is specified for each import to resolve an \"unexpected continuation byte\" error\n",
    "\n",
    "# https://www.kaggle.com/code/nelgiriyewithana/introduction-to-world-educational-data/notebook\n",
    "world_education_data = pd.read_csv(\"Data/Global_Education.csv\", encoding=\"iso-8859-1\")\n",
    "\n",
    "# https://databank.worldbank.org/source/education-statistics-%5E-all-indicators\n",
    "world_bank_education_data = pd.read_csv(\"Data/World Bank Education Data.csv\", encoding=\"ascii\")\n",
    "\n",
    "# The following are from the UNESCO Institute for Statistics Data Browser for Education available here: https://databrowser.uis.unesco.org/browser/EDUCATION/UIS-SDG4Monitoring\n",
    "teacher_data = pd.read_csv(\"Data/UIS Teacher Data/data.csv\")\n",
    "education_years_data = pd.read_csv(\"Data/UIS Years of Education/data.csv\")\n",
    "teacher_attrition_data = pd.read_csv(\"Data/UIS Teacher Attrition/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping values we do not need\n",
    "teacher_data = teacher_data.drop([\"qualifier\", \"magnitude\"], axis=1)\n",
    "education_years_data = education_years_data.drop([\"qualifier\", \"magnitude\"], axis=1)\n",
    "teacher_attrition_data = teacher_attrition_data.drop([\"qualifier\", \"magnitude\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "2024     150.0\n",
      "2011     663.0\n",
      "2012     691.0\n",
      "2013     906.0\n",
      "2014    1035.0\n",
      "2015    1090.0\n",
      "2017    1119.0\n",
      "2016    1120.0\n",
      "2018    1143.0\n",
      "2020    1147.0\n",
      "2023    1161.0\n",
      "2019    1165.0\n",
      "2022    1166.0\n",
      "2021    1199.0\n",
      "2010       NaN\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Work out which year has the most complete data\n",
    "print((teacher_data[\"year\"].value_counts() + education_years_data[\"year\"].value_counts() + teacher_attrition_data[\"year\"].value_counts()).sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2021 is the most complete year, so we will use it\n",
    "years = range(2010, 2022)\n",
    "\n",
    "new_data = pd.DataFrame(columns=[\"indicator\", \"country\"])\n",
    "\n",
    "for i in years: \n",
    "    new_data[str(i)] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data in the files is sorted by indicatorId which makes it easier to add them to our new_data dataframe\n",
    "\n",
    "def load_into_data(data: pd.DataFrame, dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    for index, _ in dataset.iterrows():\n",
    "        if index == 0:\n",
    "            lastId = None\n",
    "            lastGeo = None\n",
    "        else:\n",
    "            lastId = dataset.iloc[index -1][\"indicatorId\"]\n",
    "            lastGeo = dataset.iloc[index -1][\"geoUnit\"]\n",
    "\n",
    "        currId = dataset.iloc[index][\"indicatorId\"]\n",
    "        currGeo = dataset.iloc[index][\"geoUnit\"]\n",
    "        year = dataset.iloc[index][\"year\"]\n",
    "        \n",
    "        if year > 2021:\n",
    "            continue\n",
    "\n",
    "        if lastId != currId or lastGeo != currGeo:\n",
    "            df = pd.DataFrame({\"indicator\": [currId], \"country\": [currGeo]})\n",
    "            data = pd.concat([data, df], ignore_index=True)\n",
    "        data.at[len(data) -1, str(year)] = dataset.iloc[index][\"value\"]\n",
    "    return data\n",
    "\n",
    "new_data = load_into_data(new_data,teacher_data)\n",
    "new_data = load_into_data(new_data,education_years_data)\n",
    "new_data = load_into_data(new_data,teacher_attrition_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = new_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 9, 13, 17, 18, 19, 22, 26, 27, 28, 29, 32, 36, 40, 42, 45, 48, 53, 54, 55, 56, 58, 59, 61, 63, 64, 68, 69, 71, 72, 74, 76, 78, 82, 84, 86, 87, 88, 89, 94, 96, 97, 98, 101, 103, 107, 110, 112, 115, 118, 121, 125, 127, 133, 135, 139, 143, 148, 149, 150, 153, 159, 166, 169, 171, 174, 179, 180, 186, 190, 194, 195, 197, 201, 206, 207, 210, 212, 213, 215, 219, 222, 224, 227, 228, 229, 230, 236, 239, 241, 244, 246, 247, 248, 251, 254, 257, 260, 263, 264, 268, 272, 273, 275, 281, 283, 287, 291, 296, 299, 300, 303, 305, 314, 316, 317, 322, 328, 332, 334, 335, 337, 338, 343, 344, 345, 346, 347, 348, 349, 350, 351, 353, 354, 355, 357, 359, 361, 362, 363, 371, 372, 375, 376, 377, 378, 379, 380, 381, 383, 388, 389, 393, 396, 399, 400, 406, 408, 411, 415, 419, 420, 421, 422, 425, 429, 430, 431, 432, 435, 439, 441, 444, 446, 449, 453, 458, 459, 460, 461, 463, 464, 466, 468, 469, 473, 474, 476, 477, 479, 481, 483, 487, 489, 491, 492, 493, 494, 499, 501, 502, 503, 508, 512, 515, 517, 520, 523, 526, 530, 532, 538, 540, 544, 548, 553, 554, 555, 558, 560, 565, 572, 575, 577, 580, 585, 586, 592, 596, 600, 601, 606, 607, 612, 613, 616, 618, 619, 621, 625, 628, 630, 634, 635, 636, 637, 643, 646, 648, 651, 653, 654, 655, 658, 661, 664, 667, 670, 671, 675, 679, 680, 682, 684, 689, 691, 695, 699, 704, 707, 708, 711, 713, 722, 726, 731, 737, 741, 742, 744, 745, 746, 748, 749, 754, 755, 756, 757, 758, 759, 760, 762, 764, 765, 766, 768, 770, 773, 774, 775, 783, 785, 788, 789, 790, 791, 792, 793, 794, 796, 801, 802, 804, 806, 807, 810, 813, 814, 1041, 1190, 1384, 1418, 1420, 1421, 1424, 1428, 1430, 1431, 1436, 1437, 1438, 1439, 1441, 1446, 1450, 1452, 1454, 1455, 1456, 1461, 1462, 1464, 1465, 1470, 1471, 1472, 1473, 1477, 1479, 1483, 1490, 1493, 1494, 1495, 1502, 1503, 1505, 1506, 1507, 1508, 1510, 1511, 1513, 1515, 1516, 1519, 1524, 1525, 1527, 1528, 1530, 1531, 1532, 1536, 1537, 1538, 1540, 1546, 1551, 1553, 1554, 1556, 1557, 1560, 1561, 1562, 1563, 1565, 1570, 1571, 1574, 1576, 1578, 1582, 1583, 1584, 1586, 1587, 1588, 1592, 1594, 1599]\n"
     ]
    }
   ],
   "source": [
    "# Replacing missing values\n",
    "\n",
    "import math\n",
    "# Fill in missing 2021 values with the average of previous years\n",
    "\n",
    "# Get which indicies are missing a value of 2021.\n",
    "indexes_to_fill = []\n",
    "for index, row in new_data.iterrows():\n",
    "    if math.isnan(row[\"2021\"]):\n",
    "        indexes_to_fill.append(index)\n",
    "\n",
    "def get_average_for_row(row: pd.Series) -> float:\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for cell in row:\n",
    "        try:\n",
    "            int(cell)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if math.isnan(cell):\n",
    "            continue\n",
    "        total += cell\n",
    "        count += 1\n",
    "\n",
    "    if count == 0:\n",
    "        return 0\n",
    "    \n",
    "    return total / count\n",
    "\n",
    "print(indexes_to_fill)\n",
    "\n",
    "for i in indexes_to_fill:\n",
    "    new_data.at[i, \"2021\"] = get_average_for_row(new_data.iloc[i])\n",
    "\n",
    "new_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighting and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of Results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
